{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "818c07d546724ff29299926397a63c5814980b85"
   },
   "source": [
    "**Google Analytics Customer Revenue Prediction**\n",
    "\n",
    "To predict - How much GStore's Revenue from each customers, using EDA and ML models.\n",
    "\n",
    "Given in problem description, the 80/20 rule - 80% of revenue comes from only 20% of the customers.So our task is to predict the Gstore's revenue from those customers (using natural log of sum of all transactions per user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "5ffd9f80ec36e2ac2ac1335040a3b02f848586de"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0dfa0da1144dce3f2bd5032d78dcb402c5d95395"
   },
   "source": [
    "**Features** of the given dataset: \n",
    "* fullVisitorId- A unique identifier for each user of the Google Merchandise Store.\n",
    "* channelGrouping - The channel via which the user came to the Store.\n",
    "* date - The date on which the user visited the Store.\n",
    "* device - The specifications for the device used to access the Store.\n",
    "* geoNetwork - This section contains information about the geography of the user.\n",
    "* sessionId - A unique identifier for this visit to the store.\n",
    "* socialEngagementType - Engagement type, either \"Socially Engaged\" or \"Not Socially Engaged\".\n",
    "* totals - This section contains aggregate values across the session.\n",
    "* trafficSource - This section contains information about the Traffic Source from which the session originated.\n",
    "* visitId - An identifier for this session. This is part of the value usually stored as the _utmb cookie. This is only unique to the user. For a completely unique ID, you should use a combination of fullVisitorId and visitId.\n",
    "* visitNumber - The session number for this user. If this is the first session, then this is set to 1.\n",
    "* visitStartTime - The timestamp (expressed as POSIX time).\n",
    "\n",
    "**Note:** \n",
    "Some columns contain serialised JSON as strings which should be deserialised and converted to seperate columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "72754b71c17b37e08d47962b400904ead29692df"
   },
   "outputs": [],
   "source": [
    "def load_df(csv_path='./train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, #json.loads takes in a string and converts to dict or list object.\n",
    "                     dtype={'fullVisitorId': 'str'}, #convert id to string\n",
    "                     nrows=nrows)\n",
    "    \n",
    "\n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])  #converts semi-structured json to flat table.\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "37d1ce822f9f4bbdb2284ff8bfcd131f2b556700"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (903653, 55)\n",
      "Shape: (804684, 53)\n"
     ]
    }
   ],
   "source": [
    "train_df = load_df(\"../input/train.csv\")\n",
    "test_df = load_df(\"../input/test.csv\")\n",
    "#train_df.to_csv(\"train_sep_cols\")\n",
    "#test_df.to_csv(\"test_sep_cols\")\n",
    "#train_df = load_df(\"./train_sep_cols\")\n",
    "#test_df = load_df(\"./test_sep_cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>socialEngagementType</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>device.browser</th>\n",
       "      <th>device.browserSize</th>\n",
       "      <th>device.browserVersion</th>\n",
       "      <th>device.deviceCategory</th>\n",
       "      <th>device.flashVersion</th>\n",
       "      <th>device.isMobile</th>\n",
       "      <th>device.language</th>\n",
       "      <th>device.mobileDeviceBranding</th>\n",
       "      <th>device.mobileDeviceInfo</th>\n",
       "      <th>device.mobileDeviceMarketingName</th>\n",
       "      <th>device.mobileDeviceModel</th>\n",
       "      <th>device.mobileInputSelector</th>\n",
       "      <th>device.operatingSystem</th>\n",
       "      <th>device.operatingSystemVersion</th>\n",
       "      <th>device.screenColors</th>\n",
       "      <th>device.screenResolution</th>\n",
       "      <th>geoNetwork.city</th>\n",
       "      <th>geoNetwork.cityId</th>\n",
       "      <th>geoNetwork.continent</th>\n",
       "      <th>geoNetwork.country</th>\n",
       "      <th>geoNetwork.latitude</th>\n",
       "      <th>geoNetwork.longitude</th>\n",
       "      <th>geoNetwork.metro</th>\n",
       "      <th>geoNetwork.networkDomain</th>\n",
       "      <th>geoNetwork.networkLocation</th>\n",
       "      <th>geoNetwork.region</th>\n",
       "      <th>geoNetwork.subContinent</th>\n",
       "      <th>totals.bounces</th>\n",
       "      <th>totals.hits</th>\n",
       "      <th>totals.newVisits</th>\n",
       "      <th>totals.pageviews</th>\n",
       "      <th>totals.transactionRevenue</th>\n",
       "      <th>totals.visits</th>\n",
       "      <th>trafficSource.adContent</th>\n",
       "      <th>trafficSource.adwordsClickInfo.adNetworkType</th>\n",
       "      <th>trafficSource.adwordsClickInfo.criteriaParameters</th>\n",
       "      <th>trafficSource.adwordsClickInfo.gclId</th>\n",
       "      <th>trafficSource.adwordsClickInfo.isVideoAd</th>\n",
       "      <th>trafficSource.adwordsClickInfo.page</th>\n",
       "      <th>trafficSource.adwordsClickInfo.slot</th>\n",
       "      <th>trafficSource.campaign</th>\n",
       "      <th>trafficSource.campaignCode</th>\n",
       "      <th>trafficSource.isTrueDirect</th>\n",
       "      <th>trafficSource.keyword</th>\n",
       "      <th>trafficSource.medium</th>\n",
       "      <th>trafficSource.referralPath</th>\n",
       "      <th>trafficSource.source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>1131660440785968503</td>\n",
       "      <td>1131660440785968503_1472830385</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>1</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>desktop</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>False</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Windows</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Izmir</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>ttnet.com.tr</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Izmir</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not provided)</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>377306020877927890</td>\n",
       "      <td>377306020877927890_1472880147</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>1</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>desktop</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>False</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>dodo.net.au</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Australasia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not provided)</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>3895546263509774583</td>\n",
       "      <td>3895546263509774583_1472865386</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>1</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>desktop</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>False</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Windows</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Spain</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>unknown.unknown</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Community of Madrid</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not provided)</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>4763447161404445595</td>\n",
       "      <td>4763447161404445595_1472881213</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472881213</td>\n",
       "      <td>1</td>\n",
       "      <td>1472881213</td>\n",
       "      <td>UC Browser</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>desktop</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>False</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Linux</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>unknown.unknown</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Southeast Asia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google + online</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>27294437909732085</td>\n",
       "      <td>27294437909732085_1472822600</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472822600</td>\n",
       "      <td>2</td>\n",
       "      <td>1472822600</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>mobile</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>True</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Android</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Europe</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>unknown.unknown</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>Northern Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(not provided)</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channelGrouping          ...           trafficSource.source\n",
       "0  Organic Search          ...                         google\n",
       "1  Organic Search          ...                         google\n",
       "2  Organic Search          ...                         google\n",
       "3  Organic Search          ...                         google\n",
       "4  Organic Search          ...                         google\n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d47ae7d3baba549539adc896419dcb0baaa5e465"
   },
   "source": [
    "Lets perform EDA:\n",
    "\n",
    "Each row in the dataset is one visit to the store.\n",
    "\n",
    "Now lets check whether the given dataset conforms 80/20 rule :\n",
    "\n",
    "* First convert values of totals.transactionRevenue to float \n",
    "* Group values according to fullVisitorId ( i.e we are calculating revenue from each customer )\n",
    "* Then consider only those customers who have revenue more than zero and find out the ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "870d95b29045174fb4aa777952b04a01c48340a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique customers with non-zero revenue :  9996 and the ratio is :  0.013996726255903731\n"
     ]
    }
   ],
   "source": [
    "train_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].astype('float')\n",
    "grouped_revenue = train_df.groupby(\"fullVisitorId\")[\"totals.transactionRevenue\"].sum().reset_index()\n",
    "\n",
    "non_zero_customers = (grouped_revenue[\"totals.transactionRevenue\"]>0).sum()\n",
    "print(\"Number of unique customers with non-zero revenue : \", non_zero_customers, \"and the ratio is : \", non_zero_customers / grouped_revenue.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "So the ratio of revenue generating customers to total number of customers is 1.3%. From the above analysis it is confirmed that only 1.3% of the customers bring in revenue to Gstore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3397da66a795e1e032cbb928df0c85ca0f64bb55"
   },
   "source": [
    "**Data pre-processing:**\n",
    "\n",
    "Some columns have constant values and missing values. So, Lets examine that and drop those columns from feature set which would make our dataset more useful while training models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "798b02e13b95f98f02816b81bc627eac1a82de2d"
   },
   "outputs": [],
   "source": [
    "# convert the 'date' column values to datetime object\n",
    "import datetime\n",
    "train_df['date'] = train_df['date'].apply(lambda x: datetime.date(int(str(x)[:4]), int(str(x)[4:6]), int(str(x)[6:])))\n",
    "test_df['date'] = test_df['date'].apply(lambda x: datetime.date(int(str(x)[:4]), int(str(x)[4:6]), int(str(x)[6:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "21ffadde8972b409bbbd862dfce5cdd573ba2859"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['socialEngagementType',\n",
       " 'device.browserSize',\n",
       " 'device.browserVersion',\n",
       " 'device.flashVersion',\n",
       " 'device.language',\n",
       " 'device.mobileDeviceBranding',\n",
       " 'device.mobileDeviceInfo',\n",
       " 'device.mobileDeviceMarketingName',\n",
       " 'device.mobileDeviceModel',\n",
       " 'device.mobileInputSelector',\n",
       " 'device.operatingSystemVersion',\n",
       " 'device.screenColors',\n",
       " 'device.screenResolution',\n",
       " 'geoNetwork.cityId',\n",
       " 'geoNetwork.latitude',\n",
       " 'geoNetwork.longitude',\n",
       " 'geoNetwork.networkLocation',\n",
       " 'totals.visits',\n",
       " 'trafficSource.adwordsClickInfo.criteriaParameters']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consts = [c for c in train_df.columns if train_df[c].nunique(dropna=False)==1 ] #lets include nan values in the count(nunique())\n",
    "consts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c14480fe6ae613a6b254b6219503fe88c902ef71"
   },
   "source": [
    "As we know that train set has 55 columns whereas test set has 53 ,lets examine which of those two can be target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "37842a63f589c3bc61c75254c6fd38e2407f450a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'totals.transactionRevenue', 'trafficSource.campaignCode'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_df.columns).difference(set(test_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59ae9a092f50293243c26560967eeeb852362c30"
   },
   "source": [
    "As 'trafficSource.campaignCode' is an extra feature not in test set (other than target variable 'totals.transactionRevenue' ).Lets drop this also. Even sessionId can be removed as this is just a unique number for each visit.\n",
    "\n",
    "So lets drop consts (columns with constant values),  'sessionId', 'trafficSource.campaignCode'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "22280fbf84468dab80cc8fc15f0f1dd0cc33bba0"
   },
   "outputs": [],
   "source": [
    "cols_to_drop = consts + ['sessionId'] + [\"trafficSource.campaignCode\"]\n",
    "train_df = train_df.drop(cols_to_drop, axis=1)\n",
    "test_df = test_df.drop(cols_to_drop[:-1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf6442e295de858d14e3561a07c637cb60f0e8ce"
   },
   "source": [
    "* Fill in missing values to 0.\n",
    "* Now, Identify categorical variables and convert to numbers i.e label encode them.\n",
    "* Identify numeric variables and convert them to floats.\n",
    "\n",
    "**Note**: Do not include IDs and dates to any of the above operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "d511ef3a9e350c0c048fd38dbdf8ab93431f76a4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channelGrouping\n",
      "device.browser\n",
      "device.deviceCategory\n",
      "device.operatingSystem\n",
      "geoNetwork.city\n",
      "geoNetwork.continent\n",
      "geoNetwork.country\n",
      "geoNetwork.metro\n",
      "geoNetwork.networkDomain\n",
      "geoNetwork.region\n",
      "geoNetwork.subContinent\n",
      "trafficSource.adContent\n",
      "trafficSource.adwordsClickInfo.adNetworkType\n",
      "trafficSource.adwordsClickInfo.gclId\n",
      "trafficSource.adwordsClickInfo.page\n",
      "trafficSource.adwordsClickInfo.slot\n",
      "trafficSource.campaign\n",
      "trafficSource.keyword\n",
      "trafficSource.medium\n",
      "trafficSource.referralPath\n",
      "trafficSource.source\n",
      "trafficSource.adwordsClickInfo.isVideoAd\n",
      "trafficSource.isTrueDirect\n"
     ]
    }
   ],
   "source": [
    "#train_df.head()\n",
    "#train_df.info()\n",
    "#train_df.describe()\n",
    "\n",
    "train_df[\"totals.transactionRevenue\"].fillna(0, inplace=True)\n",
    "train_y = train_df[\"totals.transactionRevenue\"].values\n",
    "\n",
    "#identify categorical variables and label encode them.\n",
    "categorical_cols = [\"channelGrouping\", \"device.browser\", \n",
    "            \"device.deviceCategory\", \"device.operatingSystem\", \n",
    "            \"geoNetwork.city\", \"geoNetwork.continent\", \n",
    "            \"geoNetwork.country\", \"geoNetwork.metro\",\n",
    "            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n",
    "            \"geoNetwork.subContinent\", \"trafficSource.adContent\", \n",
    "            \"trafficSource.adwordsClickInfo.adNetworkType\", \n",
    "            \"trafficSource.adwordsClickInfo.gclId\", \n",
    "            \"trafficSource.adwordsClickInfo.page\", \n",
    "            \"trafficSource.adwordsClickInfo.slot\", \"trafficSource.campaign\",\n",
    "            \"trafficSource.keyword\", \"trafficSource.medium\", \n",
    "            \"trafficSource.referralPath\", \"trafficSource.source\",\n",
    "            'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.isTrueDirect']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(col)\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n",
    "    train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n",
    "    test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))\n",
    "\n",
    "\n",
    "numeric_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", \"visitStartTime\", 'totals.bounces',  'totals.newVisits']    \n",
    "for col in numeric_cols:\n",
    "    train_df[col] = train_df[col].astype(float)\n",
    "    test_df[col] = test_df[col].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c727df0fcd963153c59d59235a8a2a19342baae4"
   },
   "source": [
    "As the training set contains data from August 1st 2016 to August 1st 2017. Then take cross-validation set as last three month's data which makes the ratio of train set to cross-val set  roughly 7.5 : 2.5 .(This is considering months but not no of examples in trainset , so might not be exactly 7.5 : 2.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "ef002df940bf4403b5960ba003bcc7ed77427c57"
   },
   "outputs": [],
   "source": [
    "# Split the train dataset into development and valid based on time \n",
    "dev_df = train_df[train_df['date']<=datetime.date(2017,5,31)]\n",
    "val_df = train_df[train_df['date']>datetime.date(2017,5,31)]\n",
    "\n",
    "dev_y = np.log1p(dev_df[\"totals.transactionRevenue\"].values)\n",
    "val_y = np.log1p(val_df[\"totals.transactionRevenue\"].values)\n",
    "\n",
    "dev_X = dev_df[categorical_cols + numeric_cols] \n",
    "val_X = val_df[categorical_cols + numeric_cols] \n",
    "test_X = test_df[categorical_cols + numeric_cols] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4786d952c50855d552e25df9aa37bbe198e6dc7c"
   },
   "source": [
    "**Choosing a model to train:**\n",
    "\n",
    "As we have large dataset (with more columns >30 and rows > 10000)its better to use ensemble learning (gradient boosting models).\n",
    "\n",
    "Ensemble is a collection of predictors which come together (e.g. mean of all predictions) to give a final prediction.Boosting is an ensemble technique in which the predictors are not made independently, but sequentially (can overfit if stopping criteria isnt chosen well).\n",
    "\n",
    "The gist on how Gradient Boosting Models work is, \n",
    "* A base model is created and is used to make predictions on the whole dataset.\n",
    "* Then residual is calculated and observations which are incorrectly predicted are given higher weights.\n",
    "* The next sequential model tries to correct the errors from the previous model.\n",
    "* Similarly, multiple models are created, correcting the errors of the previous model.\n",
    "* The final model (strong learner) is the weighted mean of all the models (weak learners).\n",
    "\n",
    " e1= y - y_pred1<br> \n",
    " y_pred2 = y_pred1 + e1_pred<br>\n",
    " e2 = y - y_pred2<br> \n",
    " and so on.\n",
    " \n",
    "XGBoost and LightGBM are effiecient gradient boosting models.<br> \n",
    "XGBoost is a regularised boosting model and hence reduces overfitting. It also implements parallel processing and is faster compared to other boosting algorithms.<br>\n",
    "\n",
    "Light GBM is fast, distributed gradient boosting framework. Unlike other boosting algorithms it splits the trees leafwise and not level wise.Leaf wise splitting may lead to overfitting. This can be avoided by specifying tree-specific hyper parameters like max depth.It trains faster(on larger datasets) compared to other boosting algorithms like XGBoost.Light GBM grows tree vertically,It will choose the leaf with max delta loss to grow.  <br>\n",
    "Hence we'll use LightGBM to train our model and predict revenue from test set.\n",
    "\n",
    "Note : Light GBM is sensitive to overfitting and can easily overfit small data. So the challenge in using LGBM is hyper-parameter tuning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "83aeb1f37378a8b06c2f7ec0b5e4b923b97b8064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's rmse: 1.69586\n",
      "[200]\tvalid_0's rmse: 1.69126\n",
      "[300]\tvalid_0's rmse: 1.69175\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's rmse: 1.69087\n"
     ]
    }
   ],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\", \n",
    "        \"num_leaves\" : 30,\n",
    "        \"min_child_samples\" : 100,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.5,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    pred_val_y = model.predict(val_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, pred_val_y\n",
    "\n",
    "# Training the model #\n",
    "pred_test, model, pred_val = run_lgb(dev_X, dev_y, val_X, val_y, test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0e59b8f65ad4db19549d5d9cbad014358160c79b"
   },
   "source": [
    " Let us compute the evaluation metric on the validation data. \n",
    " * Assign zero if predicted value is less than 0.\n",
    " * Prepare a validation dataframe. As predicted values are logarithmic values apply np.exp ( we'll convert this to log values again after grouping values acc to 'fullVisitorId' and calculating sum of revenue per user )\n",
    " * Apply log on sum for all the transactions per user (or apply sum first on grouped data and then apply log).\n",
    " * Calculate rms error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "3a991ff90c88726993c105a31f03cdc7dcd2e72b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.709925685736863\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pred_val[pred_val<0] = 0\n",
    "val_pred_df = pd.DataFrame({\"fullVisitorId\":val_df[\"fullVisitorId\"].values})\n",
    "val_pred_df[\"transactionRevenue\"] = val_df[\"totals.transactionRevenue\"].values\n",
    "val_pred_df[\"PredictedRevenue\"] = np.expm1(pred_val) #exp(x) -1 can also be used but expm1 gives greater precision when converting log\n",
    "\n",
    "val_pred_df = val_pred_df.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\n",
    "val_pred_df[\"transactionRevenue\"] = np.log1p(val_pred_df[\"transactionRevenue\"].values)\n",
    "val_pred_df[\"PredictedRevenue\"] =  np.log1p(val_pred_df[\"PredictedRevenue\"].values)\n",
    "\n",
    "#Now apply rms to find out error\n",
    "print(np.sqrt(metrics.mean_squared_error(val_pred_df[\"transactionRevenue\"].values, val_pred_df[\"PredictedRevenue\"].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e04f8e58fa07429833549bd6afa254d3bd61abe"
   },
   "source": [
    "Prepare submission.csv :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "cae624b3de3a1ac1ab4948a1f7deb8622351ee3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fullVisitorId  PredictedLogRevenue\n",
      "0  0000000259678714014             0.516011\n",
      "1  0000049363351866189             0.000000\n",
      "2  0000053049821714864             0.007906\n",
      "3  0000059488412965267             0.048398\n",
      "4  0000085840370633780             0.011108\n"
     ]
    }
   ],
   "source": [
    "train_id = train_df[\"fullVisitorId\"].values\n",
    "test_id = test_df[\"fullVisitorId\"].values   \n",
    "submit_df = pd.DataFrame({\"fullVisitorId\":test_id})\n",
    "\n",
    "#Repeat same steps as we did for cross-validation\n",
    "pred_test[pred_test<0] = 0\n",
    "submit_df[\"PredictedLogRevenue\"] = np.expm1(pred_test)\n",
    "submit_df = submit_df.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\n",
    "submit_df[\"PredictedLogRevenue\"] = np.log1p(submit_df[\"PredictedLogRevenue\"])\n",
    "\n",
    "submit_df.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\n",
    "print(submit_df.head())\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6adc016ab7a60b6faf1dd9e23c07b96ae33aa13"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
